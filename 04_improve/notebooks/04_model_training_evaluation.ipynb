{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "01a56c78",
      "metadata": {
        "id": "01a56c78"
      },
      "source": [
        "# 04_model_training_evaluation.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec53e6b5",
      "metadata": {
        "id": "ec53e6b5"
      },
      "source": [
        "# Importando as bibliotecas necessárias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3523bd84",
      "metadata": {
        "id": "3523bd84",
        "outputId": "d338f0c2-ea56-4ddd-fc1a-934ecf59c2ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bibliotecas importadas com sucesso!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import joblib # Para salvar e carregar modelos\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "print(\"Bibliotecas importadas com sucesso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b68289a3",
      "metadata": {
        "id": "b68289a3"
      },
      "source": [
        "# --- 1. Carregamento do Dataset Processado da Fase ANALYZE ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cf5dbe16",
      "metadata": {
        "id": "cf5dbe16",
        "outputId": "942cd824-d423-4faa-b510-4e42ec04f951",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset 'analyzed_data.csv' carregado com sucesso!\n",
            "Primeiras 5 linhas do dataset:\n",
            "         date home_team away_team  home_score  away_score tournament     city  \\\n",
            "0  1872-11-30  Scotland   England           0           0   Friendly  Glasgow   \n",
            "1  1873-03-08   England  Scotland           4           2   Friendly   London   \n",
            "2  1874-03-07  Scotland   England           2           1   Friendly  Glasgow   \n",
            "3  1875-03-06   England  Scotland           2           2   Friendly   London   \n",
            "4  1876-03-04  Scotland   England           3           0   Friendly  Glasgow   \n",
            "\n",
            "    country  neutral    result  year  month  day_of_week  is_home_game  \\\n",
            "0  Scotland    False      Draw  1872     11            5             1   \n",
            "1   England    False  Home Win  1873      3            5             1   \n",
            "2  Scotland    False  Home Win  1874      3            5             1   \n",
            "3   England    False      Draw  1875      3            5             1   \n",
            "4  Scotland    False  Home Win  1876      3            5             1   \n",
            "\n",
            "   goal_difference  total_goals  result_numeric  \n",
            "0                0            0               0  \n",
            "1                2            6               1  \n",
            "2                1            3               1  \n",
            "3                0            4               0  \n",
            "4                3            3               1  \n",
            "\n",
            "Informações básicas do dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48335 entries, 0 to 48334\n",
            "Data columns (total 17 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   date             48335 non-null  object\n",
            " 1   home_team        48335 non-null  object\n",
            " 2   away_team        48335 non-null  object\n",
            " 3   home_score       48335 non-null  int64 \n",
            " 4   away_score       48335 non-null  int64 \n",
            " 5   tournament       48335 non-null  object\n",
            " 6   city             48335 non-null  object\n",
            " 7   country          48335 non-null  object\n",
            " 8   neutral          48335 non-null  bool  \n",
            " 9   result           48335 non-null  object\n",
            " 10  year             48335 non-null  int64 \n",
            " 11  month            48335 non-null  int64 \n",
            " 12  day_of_week      48335 non-null  int64 \n",
            " 13  is_home_game     48335 non-null  int64 \n",
            " 14  goal_difference  48335 non-null  int64 \n",
            " 15  total_goals      48335 non-null  int64 \n",
            " 16  result_numeric   48335 non-null  int64 \n",
            "dtypes: bool(1), int64(9), object(7)\n",
            "memory usage: 5.9+ MB\n"
          ]
        }
      ],
      "source": [
        "url = 'https://raw.githubusercontent.com/moises-rb/projeto_futebol_preditivo/refs/heads/main/03_analyze/data/processed/analyzed_data.csv'\n",
        "try:\n",
        "    df = pd.read_csv(url)\n",
        "    print(f\"\\nDataset 'analyzed_data.csv' carregado com sucesso!\")\n",
        "    print(\"Primeiras 5 linhas do dataset:\")\n",
        "    print(df.head())\n",
        "    print(\"\\nInformações básicas do dataset:\")\n",
        "    df.info()\n",
        "except FileNotFoundError:\n",
        "    print(f\"\\nErro: O arquivo '{url}' não foi encontrado.\")\n",
        "    print(\"Por favor, certifique-se de que o arquivo está no caminho correto.\")\n",
        "    print(\"Você pode precisar executar o notebook '03_feature_engineering_correlation.ipynb' primeiro para gerar este arquivo.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45c857eb",
      "metadata": {
        "id": "45c857eb"
      },
      "source": [
        "# --- 2. Preparação dos Dados para Modelagem ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "499aa406",
      "metadata": {
        "id": "499aa406"
      },
      "outputs": [],
      "source": [
        "# Definindo as features (X) e a variável alvo (y)\n",
        "# Remover 'date', 'home_score', 'away_score' e 'result_numeric' (já que 'result' é a categórica alvo)\n",
        "# 'city', 'country', 'tournament' são categóricas e precisarão de One-Hot Encoding\n",
        "features = ['home_team', 'away_team', 'tournament', 'city', 'country',\n",
        "            'neutral', 'year', 'month', 'day_of_week', 'is_home_game',\n",
        "            'goal_difference', 'total_goals']\n",
        "target = 'result' # 'Home Win', 'Away Win', 'Draw'\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "64dea358",
      "metadata": {
        "id": "64dea358"
      },
      "outputs": [],
      "source": [
        "# Identificando colunas numéricas e categóricas\n",
        "numerical_cols = ['year', 'month', 'day_of_week', 'goal_difference', 'total_goals']\n",
        "categorical_cols = ['home_team', 'away_team', 'tournament', 'city', 'country', 'neutral', 'is_home_game']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9a7b02e8",
      "metadata": {
        "id": "9a7b02e8"
      },
      "outputs": [],
      "source": [
        "# Criando um pré-processador para aplicar transformações diferentes a colunas diferentes\n",
        "# Standard Scaler para colunas numéricas\n",
        "# OneHotEncoder para colunas categóricas\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_cols),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "34419866",
      "metadata": {
        "id": "34419866",
        "outputId": "a05b28b9-7349-414a-95af-0eaacb468f38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do conjunto de treino: 38668 amostras\n",
            "Tamanho do conjunto de teste: 9667 amostras\n",
            "\n",
            "Distribuição das classes no conjunto de treino:\n",
            "result\n",
            "Home Win    0.490380\n",
            "Away Win    0.282197\n",
            "Draw        0.227423\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Distribuição das classes no conjunto de teste:\n",
            "result\n",
            "Home Win    0.490431\n",
            "Away Win    0.282197\n",
            "Draw        0.227371\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Divisão do dataset em conjuntos de treino e teste\n",
        "# Usaremos stratify=y para garantir que a proporção das classes da variável alvo seja mantida\n",
        "# em ambos os conjuntos (treino e teste), o que é importante para problemas de classificação.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Tamanho do conjunto de treino: {X_train.shape[0]} amostras\")\n",
        "print(f\"Tamanho do conjunto de teste: {X_test.shape[0]} amostras\")\n",
        "print(\"\\nDistribuição das classes no conjunto de treino:\")\n",
        "print(y_train.value_counts(normalize=True))\n",
        "print(\"\\nDistribuição das classes no conjunto de teste:\")\n",
        "print(y_test.value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00d74292",
      "metadata": {
        "id": "00d74292"
      },
      "source": [
        "# --- 3. Seleção e Treinamento de Modelos de Machine Learning ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "398d9a43",
      "metadata": {
        "id": "398d9a43",
        "outputId": "d9e09ec1-e2da-4106-af65-b693011b65ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Treinando Regressão Logística...\n",
            "Regressão Logística treinada!\n"
          ]
        }
      ],
      "source": [
        "# Modelo 1: Regressão Logística\n",
        "# Um pipeline para pré-processamento e modelo\n",
        "pipeline_lr = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                              ('classifier', LogisticRegression(solver='liblinear', random_state=42, max_iter=1000))])\n",
        "\n",
        "print(\"\\nTreinando Regressão Logística...\")\n",
        "pipeline_lr.fit(X_train, y_train)\n",
        "print(\"Regressão Logística treinada!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "64b3cd32",
      "metadata": {
        "id": "64b3cd32",
        "outputId": "df7f7546-f796-47f1-d22a-4c7fdc34d8fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Treinando Random Forest...\n",
            "Random Forest treinada!\n"
          ]
        }
      ],
      "source": [
        "# Modelo 2: Random Forest Classifier\n",
        "pipeline_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                              ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1))])\n",
        "\n",
        "print(\"\\nTreinando Random Forest...\")\n",
        "pipeline_rf.fit(X_train, y_train)\n",
        "print(\"Random Forest treinada!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40d0fa10",
      "metadata": {
        "id": "40d0fa10"
      },
      "source": [
        "# --- 4. Avaliação do Desempenho do Modelo ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e204c2af",
      "metadata": {
        "id": "e204c2af",
        "outputId": "f1f28711-7221-4f72-854a-ef28deb8cacd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Logistic Regression ---\n",
            "Acurácia: 0.9993\n",
            "\n",
            "Relatório de Classificação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Away Win       1.00      1.00      1.00      2728\n",
            "        Draw       1.00      1.00      1.00      2198\n",
            "    Home Win       1.00      1.00      1.00      4741\n",
            "\n",
            "    accuracy                           1.00      9667\n",
            "   macro avg       1.00      1.00      1.00      9667\n",
            "weighted avg       1.00      1.00      1.00      9667\n",
            "\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2728    0    0]\n",
            " [   7 2191    0]\n",
            " [   0    0 4741]]\n",
            "\n",
            "--- Random Forest ---\n",
            "Acurácia: 0.9983\n",
            "\n",
            "Relatório de Classificação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Away Win       1.00      1.00      1.00      2728\n",
            "        Draw       1.00      0.99      1.00      2198\n",
            "    Home Win       1.00      1.00      1.00      4741\n",
            "\n",
            "    accuracy                           1.00      9667\n",
            "   macro avg       1.00      1.00      1.00      9667\n",
            "weighted avg       1.00      1.00      1.00      9667\n",
            "\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2723    5    0]\n",
            " [  11 2187    0]\n",
            " [   0    0 4741]]\n",
            "\n",
            "--- Melhor Modelo: Logistic Regression com Acurácia de 0.9993 ---\n"
          ]
        }
      ],
      "source": [
        "models = {\n",
        "    'Logistic Regression': pipeline_lr,\n",
        "    'Random Forest': pipeline_rf\n",
        "}\n",
        "\n",
        "best_model_name = None\n",
        "best_accuracy = 0\n",
        "best_model = None\n",
        "\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    print(f\"Acurácia: {accuracy:.4f}\")\n",
        "    print(\"\\nRelatório de Classificação:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    # Atualizar o melhor modelo\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_model_name = name\n",
        "        best_model = model\n",
        "\n",
        "print(f\"\\n--- Melhor Modelo: {best_model_name} com Acurácia de {best_accuracy:.4f} ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "055cabe9",
      "metadata": {
        "id": "055cabe9"
      },
      "source": [
        "# --- 5. Interpretação do Modelo (para Random Forest) ---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b899f176",
      "metadata": {
        "id": "b899f176"
      },
      "source": [
        "    # Obter os nomes das features após o OneHotEncoding\n",
        "    # Isso é um pouco mais complexo, pois o OneHotEncoder cria muitas colunas.\n",
        "    # Vamos focar nas importâncias das features numéricas e nas principais categóricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "91e7c83b",
      "metadata": {
        "id": "91e7c83b",
        "outputId": "6afce45d-c0d1-472c-b288-a5fe0544c274",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modelo selecionado para interpretação: Logistic Regression\n",
            "Random Forest não foi o melhor modelo. Gráfico de importância de features não gerado.\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nModelo selecionado para interpretação: {best_model_name}\") # Nova linha para depuração\n",
        "\n",
        "if best_model_name == 'Random Forest':\n",
        "    print(\"Entrou no bloco de geração de gráficos para Random Forest.\") # Nova linha para depuração\n",
        "    print(\"\\n--- Importância das Features (Random Forest) ---\")\n",
        "    # Acessar o Random Forest Classifier dentro do pipeline que foi identificado como o melhor modelo\n",
        "    # best_model é o pipeline completo (pipeline_rf neste caso)\n",
        "    rf_classifier = best_model.named_steps['classifier'] # Usando best_model para garantir que é o pipeline correto\n",
        "\n",
        "    # Obter os nomes das features após o OneHotEncoding\n",
        "    ohe_feature_names = best_model.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_cols)\n",
        "    all_feature_names = numerical_cols + list(ohe_feature_names)\n",
        "\n",
        "    # Criar um DataFrame para as importâncias\n",
        "    feature_importances = pd.Series(rf_classifier.feature_importances_, index=all_feature_names)\n",
        "\n",
        "    # Exibir as top N features mais importantes\n",
        "    top_n = 15 # Ajuste conforme necessário\n",
        "    print(feature_importances.nlargest(top_n))\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(x=feature_importances.nlargest(top_n).values, y=feature_importances.nlargest(top_n).index, palette='viridis')\n",
        "    plt.title(f'Top {top_n} Features Mais Importantes (Random Forest)')\n",
        "    plt.xlabel('Importância')\n",
        "    plt.ylabel('Feature')\n",
        "    plt.show()\n",
        "else: # Adicionado para depuração\n",
        "    print(\"Random Forest não foi o melhor modelo. Gráfico de importância de features não gerado.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "05d55103",
      "metadata": {
        "id": "05d55103",
        "outputId": "900ef65c-fcf6-4ec3-e883-0db442a7d42a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Melhor modelo ('Logistic Regression') salvo em: ../models/logistic_regression_model.joblib\n",
            "\n",
            "Fase IMPROVE (Treinamento e Avaliação de Modelos) concluída neste notebook.\n",
            "Pronto para aprofundar no Controle (Fase CONTROL)!\n"
          ]
        }
      ],
      "source": [
        "# --- 6. Salvamento do Melhor Modelo ---\n",
        "output_model_dir = '../models/'\n",
        "if not os.path.exists(output_model_dir):\n",
        "    os.makedirs(output_model_dir)\n",
        "    print(f\"Diretório '{output_model_dir}' criado com sucesso para salvar modelos.\")\n",
        "\n",
        "model_filename = os.path.join(output_model_dir, f'{best_model_name.replace(\" \", \"_\").lower()}_model.joblib')\n",
        "joblib.dump(best_model, model_filename)\n",
        "print(f\"\\nMelhor modelo ('{best_model_name}') salvo em: {model_filename}\")\n",
        "\n",
        "print(\"\\nFase IMPROVE (Treinamento e Avaliação de Modelos) concluída neste notebook.\")\n",
        "print(\"Pronto para aprofundar no Controle (Fase CONTROL)!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}